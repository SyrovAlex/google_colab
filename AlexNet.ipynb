{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1i0MDebsdDuXr4lHiBkZbnfbFpc5OI52C",
      "authorship_tag": "ABX9TyM+4c2APUwjIEX7APeWii54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyrovAlex/google_colab/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-ALO9qLPWrfq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "from random import randint\n",
        "import os as os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.disable_eager_execution()"
      ],
      "metadata": {
        "id": "T9Lc2tBQb5dY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_positive_names=[]\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\"):\n",
        "\timage_positive_names.append(entry.path)\n",
        "\n",
        "image_negative_names=[]\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01484850\"):\n",
        "  image_negative_names.append(entry.path)"
      ],
      "metadata": {
        "id": "AGSYmUFOAJdD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_test=[]\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\"):\n",
        "  image_test.append(entry.path)\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\"):\n",
        "  image_test.append(entry.path)\n",
        "np.random.shuffle(image_test)"
      ],
      "metadata": {
        "id": "x4_rKxMoMgvo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_conv_layer(input, num_input_channels, num_output_channels, filter_size, stride, padding, activation, batch_norm, training, name):\n",
        "\twith tf.name_scope(name):\n",
        "\t\tshape = [filter_size, filter_size, num_input_channels, num_output_channels]\n",
        "\t\tweights = tf.Variable(tf.truncated_normal(shape, stddev=0.001), name=\"weights\")\n",
        "\t\tbiases = tf.Variable(tf.constant(0.001, shape=[num_output_channels]), name=\"biases\")\n",
        "\t\tlayer_conv = tf.nn.conv2d(input=input, filter=weights, strides=[1, stride, stride, 1], padding=padding)\n",
        "\t\tlayer_conv += biases\n",
        "\t\tif batch_norm:\n",
        "\t\t\tlayer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n",
        "\t\telse:\n",
        "\t\t\tlayer_bn=layer_conv\n",
        "\t\tlayer_act=activation(layer_bn)\n",
        "\t\treturn layer_act"
      ],
      "metadata": {
        "id": "IIoGcQhdcX6S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_pooling_layer(input, pooling, filter_size, stride, padding):\n",
        "\tlayer=pooling(input, ksize=[1,filter_size,filter_size,1], strides=[1,stride,stride,1], padding=padding)\n",
        "\treturn layer"
      ],
      "metadata": {
        "id": "L5Q3G73j-RvM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_fc_layer(input, num_inputs, num_outputs, activation, batch_norm, training,name):\n",
        "\twith tf.name_scope(name):\n",
        "\t\tweights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.001), name=\"weights\")\n",
        "\t\tbiases = tf.Variable(tf.constant(0.001, shape=[num_outputs]), name=\"biases\")\n",
        "\t\tlayer_fc = tf.matmul(input, weights) + biases\n",
        "\t\tif batch_norm:\n",
        "\t\t\tlayer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n",
        "\t\telse:\n",
        "\t\t\tlayer_bn=layer_fc\n",
        "\t\tlayer_act=activation(layer_bn)\n",
        "\t\treturn layer_act"
      ],
      "metadata": {
        "id": "pTv8GuFXdSez"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "INPUT_SIZE=227\n",
        "EPOCH=99"
      ],
      "metadata": {
        "id": "WQC1f5Hvh-gU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.placeholder(tf.float32, [BATCH_SIZE, INPUT_SIZE, INPUT_SIZE, 3])\n",
        "response_data=tf.placeholder(tf.float32, [BATCH_SIZE, 2])\n",
        "training=tf.placeholder_with_default(True, shape=(), name=\"training\")\n",
        "dropout_rate=0.5\n",
        "input_data_mean=tf.reduce_mean(input_data)"
      ],
      "metadata": {
        "id": "g16M1ZIxAh4a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0\n",
        "layer_00=new_conv_layer(input=input_data,\n",
        "                        num_input_channels=3,\n",
        "                        num_output_channels=96,\n",
        "                        filter_size=3,\n",
        "                        stride=4,\n",
        "                        padding=\"VALID\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_00\")\n",
        "layer_01=new_pooling_layer(input=layer_00,\n",
        "                           pooling=tf.nn.max_pool2d,\n",
        "                           filter_size=3,\n",
        "                           stride=2,\n",
        "                           padding=\"VALID\")\n",
        "layer_00_mean=tf.reduce_mean(layer_00)"
      ],
      "metadata": {
        "id": "YLUU4UdnAzPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45698d8-511d-4591-aef8-0d0bccdd426a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "layer_10=new_conv_layer(input=layer_01,\n",
        "                        num_input_channels=96,\n",
        "                        num_output_channels=256,\n",
        "                        filter_size=5,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_10\")\n",
        "layer_11=new_pooling_layer(input=layer_10,\n",
        "                           pooling=tf.nn.max_pool2d,\n",
        "                           filter_size=3,\n",
        "                           stride=2,\n",
        "                           padding=\"VALID\")\n",
        "layer_10_mean=tf.reduce_mean(layer_10)"
      ],
      "metadata": {
        "id": "voL8ss7HCoPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec971428-df18-4c6b-b2c8-8f351d5df0ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "layer_20=new_conv_layer(input=layer_11,\n",
        "                        num_input_channels=256,\n",
        "                        num_output_channels=384,\n",
        "                        filter_size=3,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_20\")\n",
        "layer_20_mean=tf.reduce_mean(layer_20)"
      ],
      "metadata": {
        "id": "1Q0lA4QYDTAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6aef751-2922-45ed-8f8c-17e33797c632"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "layer_30=new_conv_layer(input=layer_20,\n",
        "                        num_input_channels=384,\n",
        "                        num_output_channels=384,\n",
        "                        filter_size=3,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_30\")\n",
        "layer_30_mean=tf.reduce_mean(layer_30)"
      ],
      "metadata": {
        "id": "hRM1v70GD941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab293c1-b0cf-4376-fa10-34036ea77362"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "layer_40=new_conv_layer(input=layer_30,\n",
        "                        num_input_channels=384,\n",
        "                        num_output_channels=256,\n",
        "                        filter_size=3,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_40\")\n",
        "layer_41=new_pooling_layer(input=layer_40,\n",
        "                           pooling=tf.nn.max_pool2d,\n",
        "                           filter_size=3,\n",
        "                           stride=2,\n",
        "                           padding=\"VALID\")\n",
        "layer_40_mean=tf.reduce_mean(layer_40)"
      ],
      "metadata": {
        "id": "4L1alY84EF95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f0d537-8deb-4d0d-eae5-53b7e6805977"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = layer_41.get_shape().as_list()\n",
        "layer_reshape = tf.reshape(layer_41, [shape[0], shape[1] * shape[2] * shape[3]])"
      ],
      "metadata": {
        "id": "F-EoAdQmEr_S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_0=new_fc_layer(input=layer_reshape,\n",
        "                  num_inputs=shape[1] * shape[2] * shape[3],\n",
        "                  num_outputs=4096,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=True,\n",
        "                  training=training,\n",
        "                  name=\"fc0\")"
      ],
      "metadata": {
        "id": "Op8oGakbFSg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202ebe0c-c2ca-4ef8-d331-7d21fc9a5442"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-eebaae69ca24>:7: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_1=new_fc_layer(input=fc_0,\n",
        "                  num_inputs=4096,\n",
        "                  num_outputs=4096,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=True,\n",
        "                  training=training,\n",
        "                  name=\"fc1\")"
      ],
      "metadata": {
        "id": "1WVvw-TPGGZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47958009-e4b4-4fc8-ea02-558202019e43"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-eebaae69ca24>:7: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_2=new_fc_layer(input=fc_1,\n",
        "                  num_inputs=4096,\n",
        "                  num_outputs=1000,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=True,\n",
        "                  training=training,\n",
        "                  name=\"fc2\")"
      ],
      "metadata": {
        "id": "yU31336cGOo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d71f9eb-026e-4c1a-fa40-556e185118af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-eebaae69ca24>:7: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_3=new_fc_layer(input=fc_2,\n",
        "                  num_inputs=1000,\n",
        "                  num_outputs=2,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=False,\n",
        "                  training=training,\n",
        "                  name=\"fc3\")"
      ],
      "metadata": {
        "id": "OSOokJLOGVJ8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_conv=tf.nn.softmax(fc_3, axis=1, name=\"output\")\n",
        "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(y_conv, response_data))"
      ],
      "metadata": {
        "id": "z-bNPKaWHALE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
      ],
      "metadata": {
        "id": "5ibvNpSuIALY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predict=tf.equal(tf.argmax(fc_3,1),tf.argmax(response_data,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))"
      ],
      "metadata": {
        "id": "A-tHS7JHIgpx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess=tf.Session()\n",
        "init=tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "metadata": {
        "id": "t04XE6rcIKlS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cv2_letterbox_image(image, expected_size):\n",
        "\tih, iw = image.shape[0:2]\n",
        "\tew, eh = expected_size\n",
        "\tscale = min(eh / ih, ew / iw)\n",
        "\tnh = int(ih * scale)\n",
        "\tnw = int(iw * scale)\n",
        "\timage = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
        "\ttop = (eh - nh) // 2\n",
        "\tbottom = eh - nh - top\n",
        "\tleft = (ew - nw) // 2\n",
        "\tright = ew - nw - left\n",
        "\tnew_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)\n",
        "\treturn new_img"
      ],
      "metadata": {
        "id": "UwTxChISIqBG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "\tdef __init__(self, path_image_0, path_image_1, batch_size):\n",
        "\t\tself.path_image_0 = path_image_0\n",
        "\t\tself.path_image_1 = path_image_1\n",
        "\t\tself.index=0\n",
        "\t\tself.batch_size=batch_size\n",
        "\t\tself.img=[]\n",
        "\t\tfor entry in os.scandir(self.path_image_0):\n",
        "\t\t\tself.img.append([entry.path, 0])\n",
        "\t\tfor entry in os.scandir(self.path_image_1):\n",
        "\t\t\tself.img.append([entry.path,1])\n",
        "\t\tnp.random.shuffle(self.img)\n",
        "\n",
        "\tdef __next__(self):\n",
        "\t\timage=[]\n",
        "\t\tdata=[]\n",
        "\t\tfor i in range(self.batch_size):\n",
        "\t\t\timg=cv2.imread(self.img[self.index][0])\n",
        "\t\t\timage_letterbox=cv2_letterbox_image(img, (INPUT_SIZE, INPUT_SIZE))\n",
        "\t\t\timg_arr=np.array(image_letterbox, dtype='float32')/255.0\n",
        "\t\t\timage.append(img_arr)\n",
        "\t\t\tcls_arr=np.array([self.img[self.index][1],1-self.img[self.index][1]], dtype='float32')\n",
        "\t\t\tdata.append(cls_arr)\n",
        "\t\t\tself.index+=1\n",
        "\t\t\tif self.index==len(self.img):\n",
        "\t\t\t\tself.index=0\n",
        "\t\treturn image, data"
      ],
      "metadata": {
        "id": "CltS3XG_Q8Em"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=DataLoader(path_image_0=\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\",\n",
        "                      path_image_1=\"/content/drive/MyDrive/archive/train1-2/train1-2/n01484850\",\n",
        "\t\t\t\t\t\t\t\t\t\t\t           batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "brne3ZCGz3wK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test=DataLoader(path_image_0=\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\",\n",
        "                      path_image_1=\"/content/drive/MyDrive/archive/train1-2/train1-2/n01484850\",\n",
        "\t\t\t\t\t\t\t\t\t\t\t           batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Nv_jPcNYz8hE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCH):\n",
        "\tposition=0\n",
        "\tacc=[]\n",
        "\tfor j in range(len(data_train.img)//BATCH_SIZE):\n",
        "\t\timage_data, class_data=data_train.__next__()\n",
        "\t\tsess.run(train_step,feed_dict={input_data:image_data, response_data:class_data})\n",
        "\t\tcost=sess.run(accuracy,feed_dict={input_data:image_data, response_data:class_data})\n",
        "\t\tacc.append(cost)\n",
        "\t\t#print(\"epoch: \", i, \"iteration: \",j,\"<--->\",cost)\n",
        "\tprint(\"epoch:\", i, sum(acc)/len(acc))"
      ],
      "metadata": {
        "id": "a6QWM2L8IenF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "0dc5a67b-fd40-4133-8e2a-07591ed42a9e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 0.94296875\n",
            "epoch: 1 0.95625\n",
            "epoch: 2 0.945703125\n",
            "epoch: 3 0.956640625\n",
            "epoch: 4 0.9515625\n",
            "epoch: 5 0.971875\n",
            "epoch: 6 0.969140625\n",
            "epoch: 7 0.96796875\n",
            "epoch: 8 0.971875\n",
            "epoch: 9 0.9734375\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-3f4c22c8186b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mclass_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mclass_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;31m#print(\"epoch: \", i, \"iteration: \",j,\"<--->\",cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    969\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    970\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1192\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1372\u001b[0m                            run_metadata)\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1362\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1454\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1455\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                                             run_metadata)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}