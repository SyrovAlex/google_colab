{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1i0MDebsdDuXr4lHiBkZbnfbFpc5OI52C",
      "authorship_tag": "ABX9TyMURdZrTv52xFLCmCy5cZPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyrovAlex/google_colab/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "-ALO9qLPWrfq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "from random import randint\n",
        "import os as os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.disable_eager_execution()"
      ],
      "metadata": {
        "id": "T9Lc2tBQb5dY"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_positive_names=[]\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\"):\n",
        "\timage_positive_names.append(entry.path)\n",
        "\n",
        "image_negative_names=[]\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01484850\"):\n",
        "  image_negative_names.append(entry.path)"
      ],
      "metadata": {
        "id": "AGSYmUFOAJdD"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_test=[]\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\"):\n",
        "  image_test.append(entry.path)\n",
        "for entry in os.scandir(\"/content/drive/MyDrive/archive/train1-2/train1-2/n01443537\"):\n",
        "  image_test.append(entry.path)\n",
        "np.random.shuffle(image_test)"
      ],
      "metadata": {
        "id": "x4_rKxMoMgvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_conv_layer(input, num_input_channels, num_output_channels, filter_size, stride, padding, activation, batch_norm, training, name):\n",
        "\twith tf.name_scope(name):\n",
        "\t\tshape = [filter_size, filter_size, num_input_channels, num_output_channels]\n",
        "\t\tweights = tf.Variable(tf.truncated_normal(shape, stddev=0.001), name=\"weights\")\n",
        "\t\tbiases = tf.Variable(tf.constant(0.001, shape=[num_output_channels]), name=\"biases\")\n",
        "\t\tlayer_conv = tf.nn.conv2d(input=input, filter=weights, strides=[1, stride, stride, 1], padding=padding)\n",
        "\t\tlayer_conv += biases\n",
        "\t\tif batch_norm:\n",
        "\t\t\tlayer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n",
        "\t\telse:\n",
        "\t\t\tlayer_bn=layer_conv\n",
        "\t\tlayer_act=activation(layer_bn)\n",
        "\t\treturn layer_act"
      ],
      "metadata": {
        "id": "IIoGcQhdcX6S"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_pooling_layer(input, pooling, filter_size, stride, padding):\n",
        "\tlayer=pooling(input, ksize=[1,filter_size,filter_size,1], strides=[1,stride,stride,1], padding=padding)\n",
        "\treturn layer"
      ],
      "metadata": {
        "id": "L5Q3G73j-RvM"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_fc_layer(input, num_inputs, num_outputs, activation, batch_norm, training,name):\n",
        "\twith tf.name_scope(name):\n",
        "\t\tweights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.001), name=\"weights\")\n",
        "\t\tbiases = tf.Variable(tf.constant(0.001, shape=[num_outputs]), name=\"biases\")\n",
        "\t\tlayer_fc = tf.matmul(input, weights) + biases\n",
        "\t\tif batch_norm:\n",
        "\t\t\tlayer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n",
        "\t\telse:\n",
        "\t\t\tlayer_bn=layer_fc\n",
        "\t\tlayer_act=activation(layer_bn)\n",
        "\t\treturn layer_act"
      ],
      "metadata": {
        "id": "pTv8GuFXdSez"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "INPUT_SIZE=227\n",
        "EPOCH=99"
      ],
      "metadata": {
        "id": "WQC1f5Hvh-gU"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.placeholder(tf.float32, [BATCH_SIZE, INPUT_SIZE, INPUT_SIZE, 3])\n",
        "response_data=tf.placeholder(tf.float32, [BATCH_SIZE, 2])\n",
        "training=tf.placeholder_with_default(True, shape=(), name=\"training\")\n",
        "dropout_rate=0.5\n",
        "input_data_mean=tf.reduce_mean(input_data)"
      ],
      "metadata": {
        "id": "g16M1ZIxAh4a"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0\n",
        "layer_00=new_conv_layer(input=input_data,\n",
        "                        num_input_channels=3,\n",
        "                        num_output_channels=96,\n",
        "                        filter_size=3,\n",
        "                        stride=4,\n",
        "                        padding=\"VALID\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_00\")\n",
        "layer_01=new_pooling_layer(input=layer_00,\n",
        "                           pooling=tf.nn.max_pool2d,\n",
        "                           filter_size=3,\n",
        "                           stride=2,\n",
        "                           padding=\"VALID\")\n",
        "layer_00_mean=tf.reduce_mean(layer_00)"
      ],
      "metadata": {
        "id": "YLUU4UdnAzPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db6d69a-84d5-4349-ff9b-75e025a6c0da"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "layer_10=new_conv_layer(input=layer_01,\n",
        "                        num_input_channels=96,\n",
        "                        num_output_channels=256,\n",
        "                        filter_size=5,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_10\")\n",
        "layer_11=new_pooling_layer(input=layer_10,\n",
        "                           pooling=tf.nn.max_pool2d,\n",
        "                           filter_size=3,\n",
        "                           stride=2,\n",
        "                           padding=\"VALID\")\n",
        "layer_10_mean=tf.reduce_mean(layer_10)"
      ],
      "metadata": {
        "id": "voL8ss7HCoPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b0dfe3-0d89-4467-f236-30ac208e51a8"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "layer_20=new_conv_layer(input=layer_11,\n",
        "                        num_input_channels=256,\n",
        "                        num_output_channels=384,\n",
        "                        filter_size=3,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_20\")\n",
        "layer_20_mean=tf.reduce_mean(layer_20)"
      ],
      "metadata": {
        "id": "1Q0lA4QYDTAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7293720e-8602-4d6e-e6ed-de9f1e2cb2bb"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "layer_30=new_conv_layer(input=layer_20,\n",
        "                        num_input_channels=384,\n",
        "                        num_output_channels=384,\n",
        "                        filter_size=3,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_30\")\n",
        "layer_30_mean=tf.reduce_mean(layer_30)"
      ],
      "metadata": {
        "id": "hRM1v70GD941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd71e4e-562a-40b5-8fca-c7d5ccbb97d7"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "layer_40=new_conv_layer(input=layer_30,\n",
        "                        num_input_channels=384,\n",
        "                        num_output_channels=256,\n",
        "                        filter_size=3,\n",
        "                        stride=1,\n",
        "                        padding=\"SAME\",\n",
        "                        activation=tf.nn.relu,\n",
        "                        batch_norm=True,\n",
        "                        training=training,\n",
        "                        name=\"layer_40\")\n",
        "layer_41=new_pooling_layer(input=layer_40,\n",
        "                           pooling=tf.nn.max_pool2d,\n",
        "                           filter_size=3,\n",
        "                           stride=2,\n",
        "                           padding=\"VALID\")\n",
        "layer_40_mean=tf.reduce_mean(layer_40)"
      ],
      "metadata": {
        "id": "4L1alY84EF95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3011d0-6044-4bb9-d6e7-b223d67920c9"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-9a660c320f2a>:9: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_conv, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = layer_41.get_shape().as_list()\n",
        "layer_reshape = tf.reshape(layer_41, [shape[0], shape[1] * shape[2] * shape[3]])"
      ],
      "metadata": {
        "id": "F-EoAdQmEr_S"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_0=new_fc_layer(input=layer_reshape,\n",
        "                  num_inputs=shape[1] * shape[2] * shape[3],\n",
        "                  num_outputs=4096,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=True,\n",
        "                  training=training,\n",
        "                  name=\"fc0\")"
      ],
      "metadata": {
        "id": "Op8oGakbFSg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc60b7f-df0e-4d2f-aaa0-e78be014238b"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-126-eebaae69ca24>:7: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_1=new_fc_layer(input=fc_0,\n",
        "                  num_inputs=4096,\n",
        "                  num_outputs=4096,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=True,\n",
        "                  training=training,\n",
        "                  name=\"fc1\")"
      ],
      "metadata": {
        "id": "1WVvw-TPGGZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194f12f5-3b82-4a0b-94d6-cdf60f18075e"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-126-eebaae69ca24>:7: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_2=new_fc_layer(input=fc_1,\n",
        "                  num_inputs=4096,\n",
        "                  num_outputs=1000,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=True,\n",
        "                  training=training,\n",
        "                  name=\"fc2\")"
      ],
      "metadata": {
        "id": "yU31336cGOo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b72ce9f-c57a-40ce-ca13-a13214bc8d13"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-126-eebaae69ca24>:7: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  layer_bn=tf.layers.batch_normalization(layer_fc, training=training, momentum=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_3=new_fc_layer(input=fc_2,\n",
        "                  num_inputs=1000,\n",
        "                  num_outputs=2,\n",
        "                  activation=tf.nn.relu,\n",
        "                  batch_norm=False,\n",
        "                  training=training,\n",
        "                  name=\"fc3\")"
      ],
      "metadata": {
        "id": "OSOokJLOGVJ8"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_conv=tf.nn.softmax(fc_3, axis=1, name=\"output\")\n",
        "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(y_conv, response_data))"
      ],
      "metadata": {
        "id": "z-bNPKaWHALE"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
      ],
      "metadata": {
        "id": "5ibvNpSuIALY"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predict=tf.equal(tf.argmax(fc_3,1),tf.argmax(response_data,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))"
      ],
      "metadata": {
        "id": "A-tHS7JHIgpx"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess=tf.Session()\n",
        "init=tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "metadata": {
        "id": "t04XE6rcIKlS"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cv2_letterbox_image(image, expected_size):\n",
        "\tih, iw = image.shape[0:2]\n",
        "\tew, eh = expected_size\n",
        "\tscale = min(eh / ih, ew / iw)\n",
        "\tnh = int(ih * scale)\n",
        "\tnw = int(iw * scale)\n",
        "\timage = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
        "\ttop = (eh - nh) // 2\n",
        "\tbottom = eh - nh - top\n",
        "\tleft = (ew - nw) // 2\n",
        "\tright = ew - nw - left\n",
        "\tnew_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)\n",
        "\treturn new_img"
      ],
      "metadata": {
        "id": "UwTxChISIqBG"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCH):\n",
        "\tposition=0\n",
        "\tacc=[]\n",
        "\tfor j in range(len(image_positive_names)*2//BATCH_SIZE):\n",
        "\t\timage_data=[]\n",
        "\t\tclass_data=[]\n",
        "\t\tfor h in range(BATCH_SIZE//2):\n",
        "\t\t\timage_pos=cv2.imread(image_positive_names[position])\n",
        "\t\t\timage_neg=cv2.imread(image_negative_names[position])\n",
        "\t\t\timage_pos_letterbox=cv2_letterbox_image(image_pos, (INPUT_SIZE, INPUT_SIZE))\n",
        "\t\t\timage_neg_letterbox=cv2_letterbox_image(image_neg, (INPUT_SIZE, INPUT_SIZE))\n",
        "\t\t\timage_data.append(image_pos_letterbox)\n",
        "\t\t\tclass_data.append([1.0,0.0])\n",
        "\t\t\timage_data.append(image_neg_letterbox)\n",
        "\t\t\tclass_data.append([0.0,1.0])\n",
        "\t\t\tposition=position+1\n",
        "\t\t\t#print(class_data)\n",
        "\t\timg_data=np.array(image_data, dtype='float32')/255.0\n",
        "\t\tsess.run(train_step,feed_dict={input_data:img_data, response_data:cls_data})\n",
        "\t\tacc=[]\n",
        "\t\tfor h in range(len(image_test)):\n",
        "\n",
        "\t\tcls_data=np.array(class_data, dtype='float32')\n",
        "\t\tsess.run(train_step,feed_dict={input_data:img_data, response_data:cls_data})\n",
        "\t\tcost=sess.run(accuracy,feed_dict={input_data:img_data, response_data:cls_data})\n",
        "\t\tacc.append(cost)\n",
        "\t\t#print(\"epoch: \", i, \"iteration: \",j,\"<--->\",cost)\n",
        "\tprint(\"epoch:\", i, sum(acc)/len(acc))"
      ],
      "metadata": {
        "id": "a6QWM2L8IenF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "3c5fd68d-955a-4b58-9d48-26736a544014"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 0.95390625\n",
            "epoch: 1 0.9671875\n",
            "epoch: 2 0.96484375\n",
            "epoch: 3 0.966015625\n",
            "epoch: 4 0.971484375\n",
            "epoch: 5 0.972265625\n",
            "epoch: 6 0.96875\n",
            "epoch: 7 0.964453125\n",
            "epoch: 8 0.972265625\n",
            "epoch: 9 0.9765625\n",
            "epoch: 10 0.980078125\n",
            "epoch: 11 0.978125\n",
            "epoch: 12 0.9734375\n",
            "epoch: 13 0.966796875\n",
            "epoch: 14 0.973046875\n",
            "epoch: 15 0.98046875\n",
            "epoch: 16 0.9796875\n",
            "epoch: 17 0.9828125\n",
            "epoch: 18 0.983203125\n",
            "epoch: 19 0.9828125\n",
            "epoch: 20 0.975\n",
            "epoch: 21 0.983203125\n",
            "epoch: 22 0.980078125\n",
            "epoch: 23 0.98046875\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-8b70c182f352>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mclass_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         \u001b[0mimage_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_positive_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                         \u001b[0mimage_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_negative_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[0mimage_pos_letterbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2_letterbox_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mINPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINPUT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}